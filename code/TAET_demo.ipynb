{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2f6fcb-3755-4fd8-8b81-e40237eee5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "class Cifar10LT(Dataset):\n",
    "    def __init__(self, root, imb_factor=0.1, transform=None, train=True):\n",
    "        \"\"\"\n",
    "        Create an imbalanced CIFAR-10LT dataset.\n",
    "        :param root: Root directory where the data is stored.\n",
    "        :param imb_factor: Imbalance factor (range: (0, 1]). Smaller values indicate higher imbalance.\n",
    "        :param transform: Image preprocessing transformations.\n",
    "        :param train: Boolean indicating whether to load the training or test set.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.data, self.labels = self._load_data(root, train)\n",
    "        self.indices = self._generate_imbalance(imb_factor)\n",
    "\n",
    "    def _load_data(self, root, train):\n",
    "        \"\"\"\n",
    "        Load CIFAR-10 data from the given directory.\n",
    "        :param root: Root directory containing the CIFAR-10 dataset.\n",
    "        :param train: Boolean indicating whether to load training or test data.\n",
    "        :return: Tuple of data and labels.\n",
    "        \"\"\"\n",
    "        root = os.path.join(root, \"cifar-10-batches-py\")\n",
    "        batches = [f\"data_batch_{i}\" for i in range(1, 6)] if train else [\"test_batch\"]\n",
    "\n",
    "        data, labels = [], []\n",
    "        for batch in batches:\n",
    "            with open(os.path.join(root, batch), 'rb') as f:\n",
    "                batch_data = pickle.load(f, encoding='bytes')\n",
    "                data.append(batch_data[b'data'])\n",
    "                labels += batch_data[b'labels']\n",
    "\n",
    "        data = np.concatenate(data)\n",
    "        return data, np.array(labels)\n",
    "\n",
    "    def _generate_imbalance(self, imb_factor):\n",
    "        \"\"\"\n",
    "        Generate an imbalanced dataset based on the given imbalance factor.\n",
    "        :param imb_factor: Imbalance factor.\n",
    "        :return: List of selected indices representing the imbalanced dataset.\n",
    "        \"\"\"\n",
    "        labels = self.labels\n",
    "        num_classes = len(np.unique(labels))\n",
    "        max_samples = len(labels) // num_classes\n",
    "\n",
    "        # Calculate the number of samples per class based on the imbalance factor\n",
    "        num_samples_per_class = [\n",
    "            int(max_samples * (imb_factor ** (i / (num_classes - 1)))) for i in range(num_classes)\n",
    "        ]\n",
    "\n",
    "        indices = []\n",
    "        for class_idx in range(num_classes):\n",
    "            class_indices = np.where(labels == class_idx)[0]\n",
    "            np.random.shuffle(class_indices)\n",
    "            selected_indices = class_indices[:num_samples_per_class[class_idx]]\n",
    "            indices.extend(selected_indices)\n",
    "\n",
    "        return indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve a single sample and its label.\n",
    "        :param idx: Index of the sample to retrieve.\n",
    "        :return: Tuple of image and label.\n",
    "        \"\"\"\n",
    "        img = self.data[self.indices[idx]]\n",
    "        label = self.labels[self.indices[idx]]\n",
    "        img = np.transpose(np.reshape(img, (3, 32, 32)), (1, 2, 0))  # Convert to (H, W, C) format\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "def download_cifar10(root):\n",
    "    \"\"\"\n",
    "    Download the CIFAR-10 dataset.\n",
    "    :param root: Root directory to store the dataset.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(root):\n",
    "        os.makedirs(root)\n",
    "    torchvision.datasets.CIFAR10(root=root, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfa8c9e-4cd5-484f-abc5-c0e9cf3d706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "root = './cifar-10-batches-py'\n",
    "download_cifar10(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c9d1ec-5b0f-485f-9196-68bed5a8811b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training set: 20431\n",
      "Number of samples per class in the training set: {np.int64(0): np.int64(5000), np.int64(1): np.int64(3871), np.int64(2): np.int64(2997), np.int64(3): np.int64(2320), np.int64(4): np.int64(1796), np.int64(5): np.int64(1391), np.int64(6): np.int64(1077), np.int64(7): np.int64(834), np.int64(8): np.int64(645), np.int64(9): np.int64(500)}\n",
      "Number of samples in the test set: 4084\n",
      "Number of samples per class in the test set: {np.int64(0): np.int64(1000), np.int64(1): np.int64(774), np.int64(2): np.int64(599), np.int64(3): np.int64(464), np.int64(4): np.int64(359), np.int64(5): np.int64(278), np.int64(6): np.int64(215), np.int64(7): np.int64(166), np.int64(8): np.int64(129), np.int64(9): np.int64(100)}\n",
      "Training batch image shape: torch.Size([128, 3, 224, 224])\n",
      "Training batch label shape: torch.Size([128])\n",
      "Test batch image shape: torch.Size([128, 3, 224, 224])\n",
      "Test batch label shape: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Convert to PIL image\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.RandomCrop(224, padding=4),  # Random crop with padding\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Convert to PIL image\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Cifar10LT(root=root, imb_factor=0.1, transform=train_transform, train=True)\n",
    "test_dataset = Cifar10LT(root=root, imb_factor=0.1, transform=test_transform, train=False)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, num_workers=2, shuffle=False)\n",
    "dataloaders = {'train': train_loader, 'test': test_loader}\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Number of samples in the training set: {len(train_dataset)}\")\n",
    "unique_train_labels, train_counts = np.unique(train_dataset.labels[train_dataset.indices], return_counts=True)\n",
    "print(\"Number of samples per class in the training set:\", dict(zip(unique_train_labels, train_counts)))\n",
    "\n",
    "print(f\"Number of samples in the test set: {len(test_dataset)}\")\n",
    "unique_test_labels, test_counts = np.unique(test_dataset.labels[test_dataset.indices], return_counts=True)\n",
    "print(\"Number of samples per class in the test set:\", dict(zip(unique_test_labels, test_counts)))\n",
    "\n",
    "# Example: Iterate through training data\n",
    "for images, labels in train_loader:\n",
    "    print(\"Training batch image shape:\", images.shape)\n",
    "    print(\"Training batch label shape:\", labels.shape)\n",
    "    break  # Display only the first batch\n",
    "\n",
    "# Example: Iterate through test data\n",
    "for images, labels in test_loader:\n",
    "    print(\"Test batch image shape:\", images.shape)\n",
    "    print(\"Test batch label shape:\", labels.shape)\n",
    "    break  # Display only the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc7c96b7-f7df-45aa-95d3-b3c70a37eb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch\n",
    "model = resnet18(weights=None)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_features = model.fc.in_features  \n",
    "model.fc = nn.Linear(num_features, 10)  \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06b2767c-476a-4a2a-a46f-ecd5c2ce6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[75, 90], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69527689-4a68-40e9-9ef5-f1812a6ba909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def HARL(model,\n",
    "         x_natural,\n",
    "         y,\n",
    "         num_classes,\n",
    "         step_size=0.003,\n",
    "         epsilon=0.031,\n",
    "         perturb_steps=10,\n",
    "         alpha=0.1,\n",
    "         beta=0.1,\n",
    "         gamma=0.1,\n",
    "         distance='l_inf'):\n",
    "    \"\"\"\n",
    "    HARL: Hierarchical Adversarial Robustness Loss\n",
    "    Combines adversarial example generation (PGD) and hierarchical equalization loss into a unified loss function.\n",
    "\n",
    "    :param model: PyTorch model.\n",
    "    :param x_natural: Clean input samples [batch_size, ...].\n",
    "    :param y: Ground truth labels [batch_size].\n",
    "    :param num_classes: Number of classes in the classification task.\n",
    "    :param step_size: Step size for PGD attack.\n",
    "    :param epsilon: Perturbation size for PGD attack.\n",
    "    :param perturb_steps: Number of steps for PGD attack.\n",
    "    :param alpha: Weight for balancing the losses across classes.\n",
    "    :param beta: Weight for balancing the hierarchical equalization.\n",
    "    :param gamma: Weight for adjusting the focus on rare classes.\n",
    "    :param distance: Distance metric for the attack ('l_inf' supported).\n",
    "    :return: Computed HARL value.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Step 1: Generate adversarial examples using PGD\n",
    "    x_adv = x_natural.detach() + 0.001 * torch.randn(x_natural.shape).to(x_natural.device).detach()\n",
    "    if distance == 'l_inf':\n",
    "        for _ in range(perturb_steps):\n",
    "            x_adv.requires_grad_()\n",
    "            with torch.enable_grad():\n",
    "                loss_ce = F.cross_entropy(model(x_adv), y)\n",
    "            grad = torch.autograd.grad(loss_ce, [x_adv])[0]\n",
    "            x_adv = x_adv.detach() + step_size * torch.sign(grad.detach())\n",
    "            x_adv = torch.min(torch.max(x_adv, x_natural - epsilon), x_natural + epsilon)\n",
    "            x_adv = torch.clamp(x_adv, 0.0, 1.0)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    x_adv = Variable(torch.clamp(x_adv, 0.0, 1.0), requires_grad=False)\n",
    "    \n",
    "    # Step 2: Compute Hierarchical Equalization Loss\n",
    "    outputs = model(x_adv)  # Model outputs for adversarial examples\n",
    "    batch_size, num_classes_actual = outputs.size()\n",
    "    assert num_classes_actual == num_classes, \"Mismatch in number of classes\"\n",
    "\n",
    "    # Compute cross-entropy loss\n",
    "    pixel_loss = F.cross_entropy(outputs, y, reduction='none')\n",
    "\n",
    "    # Compute class-wise losses\n",
    "    class_losses = torch.zeros(num_classes).to(outputs.device)\n",
    "    for cls in range(num_classes):\n",
    "        mask = (y == cls).float()\n",
    "        class_loss = (pixel_loss * mask).sum() / (mask.sum() + 1e-10)\n",
    "        class_losses[cls] = class_loss\n",
    "\n",
    "    # Compute average and normalized class losses\n",
    "    avg_class_loss = class_losses.mean()\n",
    "    normalized_class_losses = class_losses / (class_losses.sum() + 1e-10)\n",
    "\n",
    "    # Loss components\n",
    "    balanced_loss = alpha * avg_class_loss\n",
    "    hierarchical_loss = beta * ((class_losses - avg_class_loss) ** 2).mean()\n",
    "    rare_class_loss = gamma * (normalized_class_losses ** 2).sum()\n",
    "\n",
    "    # Total loss\n",
    "    total_loss = balanced_loss + hierarchical_loss + rare_class_loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7d4c968-cfe7-404b-b249-af30397021b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device).squeeze()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    balanced_accuracy = balanced_accuracy_score(all_targets, all_predictions)\n",
    "    return balanced_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9979d596-c4f9-4ade-a0a7-502a9c1357ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, dataloaders, optimizer, scheduler, num_epochs=100, ce_epochs=40):\n",
    "    train_loss_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, targets in tqdm(dataloaders['train'], desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device).squeeze()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if epoch < ce_epochs:\n",
    "                loss = F.cross_entropy(outputs, targets)\n",
    "            else:\n",
    "                loss = HARL(model, inputs, targets, num_classes=10)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "        epoch_loss = running_loss / len(dataloaders['train'].dataset)\n",
    "        train_loss_history.append(epoch_loss)\n",
    "\n",
    "        # Evaluate the model after each epoch\n",
    "        balanced_accuracy = evaluate_model(model, dataloaders['test'], device)\n",
    "\n",
    "        # Output the loss and balanced accuracy\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} - Training Loss: {epoch_loss:.4f}, Test Balanced Accuracy: {balanced_accuracy:.4f}')\n",
    "\n",
    "    torch.save(model.state_dict(), \"model_final.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68206247-4e4b-46ce-b136-dff15a4f6fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training Loss: 2.2011, Test Balanced Accuracy: 0.1787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Training Loss: 1.5496, Test Balanced Accuracy: 0.2902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Training Loss: 1.3424, Test Balanced Accuracy: 0.3805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Training Loss: 1.2075, Test Balanced Accuracy: 0.3783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Training Loss: 0.2386, Test Balanced Accuracy: 0.3952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Training Loss: 0.2170, Test Balanced Accuracy: 0.4001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Training Loss: 0.2128, Test Balanced Accuracy: 0.4207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Training Loss: 0.2111, Test Balanced Accuracy: 0.4393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Training Loss: 0.2097, Test Balanced Accuracy: 0.4359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Training Loss: 0.2072, Test Balanced Accuracy: 0.4409\n"
     ]
    }
   ],
   "source": [
    "train_model(model, dataloaders, optimizer, scheduler, num_epochs=10 , ce_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62490ead-e46c-4d1b-bd14-dd742f0faa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with FGSM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating FGSM(model_name=ResNet, device=cuda:0, attack_mode=default, targeted=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM - Avg Accuracy: 0.2791, Balanced Accuracy: 0.2621 saved to attack_results.csv\n",
      "Evaluating with PGD-20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating PGD(model_name=ResNet, device=cuda:0, attack_mode=default, targeted=F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD-20 - Avg Accuracy: 0.2738, Balanced Accuracy: 0.2589 saved to attack_results.csv\n",
      "Evaluating with PGD-100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating PGD(model_name=ResNet, device=cuda:0, attack_mode=default, targeted=F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD-100 - Avg Accuracy: 0.2738, Balanced Accuracy: 0.2586 saved to attack_results.csv\n",
      "Evaluating with CW...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating CW(model_name=ResNet, device=cuda:0, attack_mode=default, targeted=Fa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CW - Avg Accuracy: 0.4160, Balanced Accuracy: 0.4038 saved to attack_results.csv\n",
      "Evaluating with AutoAttack...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating AutoAttack(model_name=ResNet, device=cuda:0, attack_mode=default, tar"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoAttack - Avg Accuracy: 0.2260, Balanced Accuracy: 0.2011 saved to attack_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm  \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "from torchattacks import FGSM, PGD, CW, DeepFool, AutoAttack\n",
    "from collections import defaultdict\n",
    "\n",
    "# Assuming `test_dataset` and `model` are already defined\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 10  # Assuming there are 10 classes\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "def evaluate_model_with_attack_by_class(model, dataloader, attack, num_classes):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance under adversarial attack for each class.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The model to be evaluated.\n",
    "    - dataloader: DataLoader providing test data.\n",
    "    - attack: The adversarial attack to evaluate.\n",
    "    - num_classes: The number of classes in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - class_accuracies: Accuracy for each class.\n",
    "    - avg_accuracy: Overall average accuracy.\n",
    "    - balanced_accuracy: Accuracy averaged equally across all classes.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Iterate over test data with progress bar\n",
    "    for images, labels in tqdm(dataloader, desc=f'Evaluating {attack}'):\n",
    "        labels = labels.cuda()\n",
    "        images = attack(images.cuda(), labels).cpu()  # Apply the attack\n",
    "        outputs = model(images.cuda())\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Record results per class\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i].item()\n",
    "            class_total[label] += 1\n",
    "            class_correct[label] += (predicted[i] == label).item()\n",
    "\n",
    "    # Calculate accuracy for each class\n",
    "    class_accuracies = {}\n",
    "    for class_idx in range(num_classes):\n",
    "        if class_total[class_idx] > 0:\n",
    "            class_accuracies[class_idx] = class_correct[class_idx] / class_total[class_idx]\n",
    "        else:\n",
    "            class_accuracies[class_idx] = None\n",
    "\n",
    "    # Calculate overall average accuracy\n",
    "    avg_accuracy = total_correct / total_samples\n",
    "\n",
    "    # Calculate balanced accuracy (mean per-class accuracy)\n",
    "    balanced_accuracy = np.mean([acc for acc in class_accuracies.values() if acc is not None])\n",
    "\n",
    "    return class_accuracies, avg_accuracy, balanced_accuracy\n",
    "\n",
    "\n",
    "def save_result_to_csv(attack_name, class_accuracies, avg_accuracy, balanced_accuracy, filename='attack_results.csv'):\n",
    "    \"\"\"\n",
    "    Save attack results to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - attack_name: Name of the adversarial attack.\n",
    "    - class_accuracies: Accuracy for each class.\n",
    "    - avg_accuracy: Overall average accuracy.\n",
    "    - balanced_accuracy: Accuracy averaged equally across all classes.\n",
    "    - filename: Name of the CSV file to save the results.\n",
    "    \"\"\"\n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write per-class accuracies\n",
    "        for class_idx, accuracy in class_accuracies.items():\n",
    "            writer.writerow([f'{attack_name} - Class {class_idx}', accuracy])\n",
    "        \n",
    "        # Write overall and balanced accuracies\n",
    "        writer.writerow([f'{attack_name} - Avg Accuracy', avg_accuracy, ''])\n",
    "        writer.writerow([f'{attack_name} - Balanced Accuracy', balanced_accuracy, ''])\n",
    "        print(f'{attack_name} - Avg Accuracy: {avg_accuracy:.4f}, Balanced Accuracy: {balanced_accuracy:.4f} saved to {filename}')\n",
    "\n",
    "\n",
    "# Initialize the CSV file with headers\n",
    "with open('attack_results.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Attack', 'Accuracy'])\n",
    "\n",
    "# Define attacks to evaluate\n",
    "attacks = [\n",
    "    ('FGSM', FGSM(model, eps=8/255)),\n",
    "    ('PGD-20', PGD(model, eps=8/255, alpha=1/255, steps=20)),\n",
    "    ('PGD-100', PGD(model, eps=8/255, alpha=1/255, steps=100)),\n",
    "    ('CW', CW(model, c=10, kappa=0, steps=100, lr=0.01)),\n",
    "    ('AutoAttack', AutoAttack(model, norm='Linf', eps=8/255, version='standard', n_classes=NUM_CLASSES, seed=None, verbose=False))\n",
    "]\n",
    "\n",
    "# Evaluate each attack and save results\n",
    "for attack_name, attack in attacks:\n",
    "    print(f'Evaluating with {attack_name}...')\n",
    "    class_accuracies, avg_accuracy, balanced_accuracy = evaluate_model_with_attack_by_class(model, test_loader, attack, NUM_CLASSES)\n",
    "    save_result_to_csv(attack_name, class_accuracies, avg_accuracy, balanced_accuracy, filename='attack_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbed82d6-d645-4327-8781-adfef970d4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
